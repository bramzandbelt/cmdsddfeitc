---
params:
  title: "03_computational_modeling_analysis"
  participant_id: 1   # identifier of participant in the study
  model_name: "DDM" # name of the model class to fit to the data
  parameterization: "time_scaling" # name of the parameterization to fit to the data
  bound_setting: "wide" # whether to use standard or wide bounds on parameter values
  algorithm: "DEoptimR"
  par_vals: !r c(0.6057, 1, 0.7458, 1, 1.0564, 0.9371, 4.9486, 1.088) # when optimize = FALSE, report is generated using these values
  max_iter: 5000 # maximum number of iterations
  rel_tol: 0.00000001 # relative tolerance
  n_pop_per_free_param: 20
  optimize: TRUE
  visualize: FALSE
  pars_from_file: TRUE
title: '`r stringr::str_c(stringr::str_to_title(params$title), " - participant ", params$participant_id)`'
subtitle: '`r stringr::str_c(stringr::str_to_upper(params$model_name), params$parameterization, stringr::str_c(params$bound_setting, " bounds"), params$algorithm, sep = " - ")`'
author: "Bram Zandbelt"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    number_sections: true
    df_print: paged
    code_folding: hide
    theme: readable
    highlight: pygments
    bibliography: "cmdsddfeitc.bib"
    biblio-style: author-year
---

```{r setup, include=FALSE}
# Set root dir to project directory to ensure that code is always run relative to the project directory, no matter if it is run using `knitr` or interactively.
knitr::opts_knit$set(root.dir = rprojroot::find_root(rprojroot::has_file("DESCRIPTION")))

# Attach tideverse package to enable access to pipe (%>%)
require(tidyverse)
```

# Overview

This notebook contains the __computational modeling analysis__ of an individual participant's data. The goal of this analysis is to determine the fit the intertemporal choice task performance data with a cognitive model, parameterized in a certain way to account for the framing effects.

The tasks that can be fit are:

- defer-speedup task;
- date-delay task.

The models the can be used to fit the task performance are:

- Drift Diffusion Model (`DDM`, choices and response times);  
- Decision Field Theory (`DFT_C`, choices only; `DFT_CRT`, choices and response times),

The parameterizations that can used to account for the framing effects are:

- time scaling parameter ($\kappa$);
- value scaling parameter ($\mu$);
- time scaling parameter ($\kappa$) and value scaling parameter ($\mu$);
- time scaling parameter ($\kappa$) and non-decision-time ($T_{ER}$);
- value scaling parameter ($\mu$) and non-decision-time ($T_{ER}$);
- time scaling parameter ($\kappa$), value scaling parameter ($\mu$), and non-decision-time ($T_{ER}$);

This notebook takes as input a participant's cleaned and preprocessed experiment data and produces as output visualizations and csv files written to disk of optimization statistics, best-fitting model parameter values, model fit to the data, and predicted indifference point curves and area under the curve statistics.

# Preliminaries

Before reading the data, the following is specified:

```{r Define notebook name, based on YAML header}
notebook_name <- 
   stringr::str_to_lower(stringr::str_replace_all(params$title, " ", "_"))
```
- the _name of the notebook (`notebook_name`)_, which is used to save output (e.g. best-fitting parameters, a visual report) to a notebook-specific directory;

```{r Define relevant directories for reading and writing data and create whenever needed}
# Raw trial log files are read from here
preprocessed_data_dir <- 
  file.path("data","derivatives", "01_preprocessing", "included")

# Model optimization data will be written here
optimizations_dir <- 
  file.path("data","derivatives", notebook_name)
converged_models_dir <- 
  file.path(optimizations_dir, "converged")
nonconverged_models_dir <- 
  file.path(optimizations_dir, "nonconverged")

# Create non-existing dirs if they don't exist
cmdsddfeitc::check_dir(all_dirs = c(preprocessed_data_dir, 
                                    optimizations_dir,
                                    converged_models_dir,
                                    nonconverged_models_dir))
```
- all _relevant directories_ for reading and writing data

```{r File name and task version}
# Determine which file should be read
expt_standard_trials_filename <- list.files(path = preprocessed_data_dir, 
                                            pattern = sprintf("^experiment_standard_trials_.*%.3d.csv$",
                                                              params$participant_id[[1]])
                                            )

# Determine task version, because factor levels (e.g. framing, trial_type) are task-dependent
task_version <- ifelse(stringr::str_detect(expt_standard_trials_filename, "defer_speedup"),
                    "defer_speedup",
                    ifelse(stringr::str_detect(expt_standard_trials_filename, "date_delay"),
                           "date_delay",
                           NA
                           )
                    )
```
- the paths to the _task performance files (`expt_standard_trials_filename`)_ containing the data from the cleaned standard trials from the experiment and the  _task version (`task_version`).

```{r Define some variables relevant for modeling}
# Parameterization & framing levels
parameterization <- 
  ifelse(params$parameterization == "one_condition",
         params$parameterization,
         stringr::str_c(task_version, "_", params$parameterization)
         )

if (task_version == "defer_speedup") {
  framing_levels <- c("neutral", "defer", "speedup")
} else if (task_version == "date_delay") {
  framing_levels <- c("delay", "date")
}

# Parameter bounds
lowers <- itchmodel::get_par_bounds(model = params$model_name,
                                    parameterization = parameterization,
                                    bound = 'lower',
                                    bound_setting = params$bound_setting)
uppers <- itchmodel::get_par_bounds(model = params$model_name,
                                    parameterization = parameterization,
                                    bound = 'upper',
                                    bound_setting = params$bound_setting)

# Number of free parameters
n_free_params <- sum(!(lowers == uppers))

# Parameter names
par_names <- itchmodel::get_par_names(model = params$model_name, parameterization = parameterization)
par_names <- factor(par_names, levels = par_names, ordered = TRUE)

free_par_names <- 
  par_names[!(lowers == uppers)]

free_par_lowers <- lowers[!(lowers == uppers)]
names(free_par_lowers) <- free_par_names
free_par_uppers <- uppers[!(lowers == uppers)]
names(free_par_uppers) <- free_par_names

# Tibble with bound values of free params
free_par_bounds_tibb <- 
  dplyr::bind_rows(free_par_lowers, free_par_uppers) %>% 
  dplyr::mutate(bound = c("lower", "upper")) %>% 
  dplyr::select(bound, dplyr::everything())

```
- several variables relevant for modeling, including the _parameterization (`_parameterization`)_,  _framing levels (`framing_levels`)_, _parameter bounds (`lowers`, `uppers`)_, among others.

```{r Determine indifference points based on model fits}
# Determine indifference points, given LL amount, LL delay, and best-fitting parameters
predict_ip <- function(m_l, t_l, parameters, frame) {
  
  if (frame == 'defer') {
    numerator_lh <- as.double(parameters["w"]) * 1 * m_l^as.double(parameters["alpha"])
  } else {
    numerator_lh <- as.double(parameters["w"]) * as.double(parameters["mu"]) * m_l^as.double(parameters["alpha"])
  }
  
  numerator_rh <- as.double(1 - (parameters["w"])) * as.double(parameters["kappa"]) * t_l^as.double(parameters["beta"])
  numerator <- numerator_lh - numerator_rh
  
  if (frame == 'speedup') {
    denominator <- as.double(parameters["w"]) * 1
  } else {
    denominator <- as.double(parameters["w"]) * as.double(parameters["mu"])
  }
  
  frac <- numerator/denominator
  frac[frac < 0] <- 0
  
  return(10^(log10(frac)/as.double(parameters["alpha"])))
  
}

```
- function for computing indifference points (`predict_ip`), based on amounts, delays, parmeter values, and frame.

# Read data

Having specified all relevant variables, the cleaned standard trials from the experiment are read:
```{r Read trial_log data, warning=FALSE}
# Read (and print) the data, using task-dependent column specifications
(expt_trials <-
    readr::read_csv(file = file.path(preprocessed_data_dir, expt_standard_trials_filename),
                    col_types = cmdsddfeitc::get_col_types(stringr::str_c("expt_standard_trials_",
                                                                          task_version)))
  )

# Get rid of trials that won't be used
if (params$parameterization == "one_condition") {
  if (task_version == "defer_speedup") {
    frame_cond <- "neutral"
  } else if (task_version == "date_delay") {
    frame_cond <- "delay"
  }
  
  expt_trials <- 
    expt_trials %>% 
    dplyr::filter(frame == frame_cond) %>%
    dplyr::mutate(frame = forcats::fct_drop(.$frame))
    
}

# Number of data points
n_data_points <- nrow(expt_trials)
```

# Preprocess data

The task performance data is then cleaned and formatted for modeling and plotting purposes:

```{r Prepare observed data for modeling}
# Delays for which to compute AUC
delays_ip <- seq(0,max(expt_trials$t_l),1)

# Count the number of data points
n_data_points <- nrow(expt_trials)

# Tidy & nest the observational data, as to prepare them for modeling
obs_nested <- 
  cmdsddfeitc::tidy_obs_prd_choice_rt(return_var = "obs",
                                      obs = expt_trials)$obs_nested

```
- For modeling, the data is nested by frame and grouped into stimuli and observation variables.


## Prepare observed data for plotting

```{r Prepare observed data for plotting}
if (params$visualize) {
  obs_for_plotting <- 
    obs_nested %>%
    dplyr::select(-stimuli, -observations) %>%
    tidyr::unnest()
  
  obs_for_plotting
}
```
- For plotting, probability of choosing LL ($P(LL)$) is computed for each combination of frame (2 or 3 levels, depending on task), delay (7 levels), and SS amount category (3 levels).

# Analyze data

## Fit model to the data or just compute log-likelihood for given parameter values

```{r Fit model to the data, warning=FALSE, results=FALSE}
# Set seed for the random number generator, so that results can be reproduced
set.seed(19821101) # That's my DOB

if (params$optimize) {
  
  if (params$algorithm == "DEoptim") {
    # Optimization using bound constraints only
    
    optim_out <- 
     DEoptim::DEoptim(fn = itchmodel::get_log_likelihood, # optimization function
                      lower = lowers, # lower bounds
                      upper = uppers, # upper bounds
                      control = list(itermax = params$max_iter, 
                                     reltol = params$rel_tol,
                                     steptol = 200,
                                     NP = params$n_pop_per_free_param * n_free_params,
                                     trace = TRUE
                                     ),
                      # Additional arguments passed to fn and constr:
                      data = obs_nested,
                      model = params$model_name,
                      parameterization = parameterization
                      )
    
    # Store optimization function value and parameter values in variables ------
    optim_val_per_iter <- optim_out$member$bestvalit
    par_vals_per_iter <- optim_out$member$bestmemit
    n_iter <- optim_out$optim$iter
    colnames(par_vals_per_iter) <- par_names
    
    best_optim_val <- unname(optim_out$optim$bestval)
    best_par_val <- unname(optim_out$optim$bestmem)
    
  } else if (params$algorithm == "DEoptimR") {
    
    # DEoptimR took very long and very slowly converged to run for DDM models. 
    # To address this, we start from the best-fitting DDM parameters obtained 
    # with the DEoptim algorithm
    if (params$pars_from_file) {
      # Load the best-fitting parameters obtained with DEoptim, if this file exists
      
      best_par_val_file <-
        list.files(path = converged_models_dir,
                   pattern = sprintf("^best_fitting_params_task-.*_pid-%.3d_model-%s_pmz-%s_bounds-%s_algorithm-%s_BIC.*.csv$",
                                     params$participant_id, # pid
                                     params$model_name, # model
                                     params$parameterization, # pmz
                                     params$bound_setting, # bounds
                                     "DEoptim" # algorithm
                                     )
                   )
    } else {
      best_par_val_file <- "NA"
    }
    
    
    if (file.exists(file.path(converged_models_dir, best_par_val_file))) {
      best_par_val <-
        readr::read_csv(file = file.path(converged_models_dir, best_par_val_file),
                        col_types = readr::cols()) %>%
        dplyr::select(-participant_id, -model_name, -parameterization, -bound_settings, -algorithm) %>%
        as.double()
      
      optim_val_per_iter <- rep(NA, params$max_iter)
      par_vals_per_iter <- matrix(nrow = params$max_iter, ncol = length(lowers))
      colnames(par_vals_per_iter) <- par_names
      
      this_optim_val <- 1e6
      iter <- 0
      optim_out <- 
        list(convergence = 1)
      
      while (optim_out$convergence == 1 & iter <= (params$max_iter - 1)) {
        
        iter <- iter + 1
        
        optim_out <- 
       DEoptimR::JDEoptim(fn = itchmodel::get_log_likelihood, # optimization function
                          lower = lowers, # lower bounds
                          upper = uppers, # upper bounds
                          meq = 0,
                          constr = itchmodel::get_nonlinear_constraints,
                          maxiter = 1,
                          tol = params$rel_tol,
                          add_to_init_pop = as.matrix(best_par_val),
                          trace = TRUE,
                          details = TRUE,
                          # Additional arguments passed to fn and constr:
                          data = obs_nested,
                          model = params$model_name,
                          parameterization = parameterization,
                          pcrit = c(.75, .25)
                        )
        
        optim_val_per_iter[iter] <- optim_out$value
        par_vals_per_iter[iter,] <- optim_out$par
      }
      
    } else {
      
      # Optimization using bound constraints and nonlinear constraints
      # - Since DEoptimR::JDEoptim does not return iteration-wise optimization 
      #   function values and parameter values, we implement this two step metho
    
      
      # Step 1 - Find reasonable starting parameter values (i.e. with likelihoods 
      #   between 0.01 and 0.99 for all trials)
      optim_val_per_iter <- rep(NA, params$max_iter)
      par_vals_per_iter <- matrix(nrow = params$max_iter, ncol = length(lowers))
      colnames(par_vals_per_iter) <- par_names
      
      this_optim_val <- 1e6
      iter <- 1
      
      while (this_optim_val >= 1e6) {
        # This ensures that reasonable starting parameter values (i.e. likelihoods between 0.01 and 0.99 for all trials)
        optim_out <-
          DEoptimR::JDEoptim(fn = itchmodel::get_log_likelihood, # optimization function
                             lower = lowers, # lower bounds
                             upper = uppers, # upper bounds
                             constr = itchmodel::get_nonlinear_constraints,
                             meq = 0,
                             maxiter = 1,
                             tol = params$rel_tol,
                             NP = params$n_pop_per_free_param * n_free_params,
                             trace = TRUE,
                             details = TRUE,
                             # Additional arguments passed to fn and constr:
                             data = obs_nested,
                             model = params$model_name,
                             parameterization = parameterization,
                             pcrit = c(.75, .25)
                             )
        
        this_optim_val <- optim_out$value
        optim_val_per_iter[iter] <- optim_out$value
        par_vals_per_iter[iter,] <- optim_out$par
      }
      
      # Step 2 - Optimize parameter values and store intermediate optimization
      # function value and parameter values
      while (optim_out$convergence == 1 & iter <= (params$max_iter - 1)) {
        
        iter <- iter + 1
        
        optim_out <- 
         DEoptimR::JDEoptim(fn = itchmodel::get_log_likelihood, # optimization function
                            lower = lowers, # lower bounds
                            upper = uppers, # upper bounds
                            meq = 0,
                            constr = itchmodel::get_nonlinear_constraints,
                            maxiter = 1,
                            tol = params$rel_tol,
                            NP = 0,
                            add_to_init_pop = optim_out$poppar,
                            trace = TRUE,
                            details = TRUE,
                            # Additional arguments passed to fn and constr:
                            data = obs_nested,
                            model = params$model_name,
                            parameterization = parameterization,
                            pcrit = c(.75, .25)
                          )
        
        optim_val_per_iter[iter] <- optim_out$value
        par_vals_per_iter[iter,] <- optim_out$par
      }
    }
    
    # Store optimization function value and parameter values in variables ------
    best_optim_val <- optim_out$value
    best_par_val <- optim_out$par
    n_iter <- iter
  }
  
  # Convert optim_val_per_iter to tidy tibble for plotting purposes
  optim_val_per_iter_tibb <- 
    tibble::as.tibble(na.exclude(optim_val_per_iter))
  colnames(optim_val_per_iter_tibb) <- "fun_val"
  optim_val_per_iter_tibb <- 
    optim_val_per_iter_tibb %>%
    dplyr::mutate(iter = 1:n()) %>%
    dplyr::select(iter, fun_val)
  
  # Convert par_vals_per_iter to tidy tibble for plotting  and saving purposes
  par_vals_per_iter_tibb <- 
    tibble::as.tibble(na.exclude(par_vals_per_iter)) %>% 
    dplyr::mutate(iter = 1:n()) %>% 
    dplyr::select(iter, as.character(par_names)) %>%
    tidyr::drop_na()
    
  free_par_vals_per_iter_tibb <- 
    par_vals_per_iter_tibb %>%
    dplyr::select(iter, as.character(free_par_names)) %>%
    tidyr::gather(key = "key",
                  value = "value",
                  as.character(free_par_names),
                  factor_key = TRUE)
  
} else {
  # Do not optimize, but use parameter values loaded from disk or specified in params$par_vals
  
  if (params$pars_from_file) {
    
    # Optimization output statistics: used to determined convergence
    optim_out_stats_file_pattern <- 
      sprintf("^optim_stats_task-.*_pid-%.3d_model-%s_pmz-%s_bounds-%s_algorithm-%s_BIC.*.csv$",
              params$participant_id, # pid
              params$model_name, # model
              params$parameterization, # pmz
              params$bound_setting, # bounds
              params$algorithm # algorithm
              )
    
    optim_out_stats_file <- 
      list.files(path = converged_models_dir,
                 pattern = optim_out_stats_file_pattern
                 )
    
    # If the file is empty, it is possible that the optimization has not converged onto a minimum, so check nonconverged_models_dir
    if (length(optim_out_stats_file) == 0) {
      optim_out_stats_file <- 
        list.files(path = nonconverged_models_dir,
                   pattern = optim_out_stats_file_pattern
                   )
      source_data_dir <- nonconverged_models_dir
    } else {
      source_data_dir <- converged_models_dir
    }
      
    
    assertthat::assert_that(length(optim_out_stats_file) == 1,
                            msg = "Multiple (or no) optimization output files (optim_out_stats_file) detected; unclear which one to select.")
    
    optim_out_stats <- 
      readr::read_csv(file.path(source_data_dir, optim_out_stats_file),
                      col_types = readr::cols())
    n_iter <- optim_out_stats$n_iter
    
    optim_val_per_iter_file <- 
      list.files(path = source_data_dir,
                 pattern = sprintf("^evolution_of_fun_val_across_iters_task-.*_pid-%.3d_model-%s.*_pmz-%s_bounds-%s_algorithm-%s.*.csv$",
                                   params$participant_id, # pid
                                   params$model_name, # model
                                   params$parameterization, # pmz
                                   params$bound_setting, # bounds
                                   params$algorithm # algorithm
                                   )
                 )
    
    assertthat::assert_that(length(optim_val_per_iter_file) == 1,
                            msg = "Multiple optimization value files (optim_val_per_iter_file) detected; unclear which one to select.")
      
    optim_val_per_iter_tibb <- 
      readr::read_csv(file.path(source_data_dir, optim_val_per_iter_file),
                      col_types = readr::cols()) %>%
      tidyr::drop_na() %>%
      dplyr::select(iter, fun_val)
    
    best_optim_val <- 
      optim_val_per_iter_tibb %>% 
      dplyr::slice(n_iter) %>% # Last entry is best value
      dplyr::pull(fun_val)
    
    par_vals_per_iter_file <- 
      list.files(path = source_data_dir,
                 pattern = sprintf("^evolution_of_params_across_iters_task-.*_pid-%.3d_model-%s_pmz-%s_bounds-%s_algorithm-%s_BIC.*.csv$",
                                   params$participant_id, # pid
                                   params$model_name, # model
                                   params$parameterization, # pmz
                                   params$bound_setting, # bounds
                                   params$algorithm # algorithm
                                   )
                 )
    
    assertthat::assert_that(length(par_vals_per_iter_file) == 1,
                            msg = "Multiple parameter values files (par_vals_per_iter_file) detected; unclear which one to select.")
    
    par_vals_per_iter <- 
      readr::read_csv(file.path(source_data_dir, par_vals_per_iter_file),
                      col_types = readr::cols()) %>%
      dplyr::select(iter, as.character(par_names)) %>%
      tidyr::drop_na()
    
    free_par_vals_per_iter_tibb <- 
      par_vals_per_iter %>%
      dplyr::select(iter, as.character(free_par_names)) %>%
      tidyr::gather(key = "key",
                    value = "value",
                    as.character(free_par_names),
                    factor_key = TRUE)
    
    best_par_val_file <-
      list.files(path = source_data_dir,
                 pattern = sprintf("^best_fitting_params_task-.*_pid-%.3d_model-%s_pmz-%s_bounds-%s_algorithm-%s.*.csv$",
                                   params$participant_id, # pid
                                   params$model_name, # model
                                   params$parameterization, # pmz
                                   params$bound_setting, # bounds
                                   params$algorithm # algorithm
                 )
      )

    assertthat::assert_that(length(best_par_val_file) == 1,
                            msg = "Multiple best-fitting parameter values files (best_par_val_file) detected; unclear which one to select.")
    
    best_par_val <-
      readr::read_csv(file = file.path(source_data_dir, best_par_val_file),
                      col_types = readr::cols()) %>%
      dplyr::select(-participant_id, -model_name, -parameterization, -bound_settings, -algorithm) %>%
      as.double()
    
    # Further processing of par_vals_per_iter for use in optim_stat
    par_vals_per_iter <- 
      par_vals_per_iter %>%
      dplyr::select(-iter)
    colnames(par_vals_per_iter) <- 
      stringr::str_c("par", seq(1,length(best_par_val)))
    par_vals_per_iter <- 
      par_vals_per_iter %>%
      as.matrix()
    
  } else {
    
    # Parameter values (N.B. not necessarily best-fitting, but for naming consistency)
    best_par_val <- params$par_vals
    
    n_iter <- 1
      
    par_vals_per_iter_tibb <- 
      best_par_val %>% 
      tibble::as.tibble() %>% 
      dplyr::mutate(key = par_names) %>% 
      tidyr::spread(key = key, value = value) %>%
      dplyr::mutate(iter = n_iter) %>%
      dplyr::select(iter, dplyr::everything())
    
    free_par_vals_per_iter_tibb <- 
      par_vals_per_iter_tibb %>%
      dplyr::select(iter, as.character(free_par_names)) %>%
      tidyr::gather(key = "key",
                    value = "value",
                    as.character(free_par_names),
                    factor_key = TRUE)
    
    # Compute negative log-likelihood
    negative_log_likelihood <- 
      itchmodel::get_log_likelihood(x = best_par_val,
                                    data = obs_nested,
                                    model = params$model_name,
                                    parameterization = parameterization)
    
    optim_val_per_iter_tibb <- 
      tibble::tibble(iter = 1,
                     fun_val = negative_log_likelihood)
    
    best_optim_val <- negative_log_likelihood
      
  }
  
  # Make mock optim_out variable for the rest of the notebook code to work
  if (params$algorithm == "DEoptim") {
    optim_out <- 
    list(member = list(bestvalit = best_optim_val,
                       bestmemit = ifelse(params$pars_from_file,
                                          par_vals_per_iter,
                                          matrix(best_par_val, 
                                                 nrow = 1, 
                                                 dimnames = list(1,
                                                                 stringr::str_c("par", seq(1,length(best_par_val))))
                                                 )
                                          ),
                       bestmem = best_par_val),
         optim = list(bestval = best_optim_val,
                      iter = ifelse(params$pars_from_file,
                                    nrow(par_vals_per_iter),
                                    1)
                      )
         )
  } else if (params$algorithm == "DEoptimR") {
    
    optim_out <- 
      list(value = best_optim_val,
           par = best_par_val,
           iter = ifelse(params$pars_from_file,
                         nrow(par_vals_per_iter),
                         1),
           convergence = ifelse(params$pars_from_file,
                                ifelse(optim_out_stats$converged,
                                       0, #  0 indicates successful completion
                                       1), #  1 means that iteration limits has been reached
                                1)
             
             
           )
  }
}

# Store best-fitting parameter values per frame in a variable for later use
best_par_val_per_frame <- 
    itchmodel::get_par_values(x = best_par_val, 
                              model = params$model_name, 
                              parameterization = parameterization)
  if (!is.list(best_par_val_per_frame)) {
    best_par_val_per_frame <- list(best_par_val_per_frame)
  }
```
If `params$optimize` is set to `TRUE`, the model (`params$model_name`) with a certain parameterization (`params$parameterization`) is fit to the data. Depending on the model, only choices are fit (`DFT_C`) or both choices and response times are fit (`DDM`, `DFT_CRT`). Model parameter values are optimized by minimizing negative log-likelihood using a differential evolution algorithm with bounds and nonlinear constraints (`DEOptimR`) or with bounds only (`DEoptim`). The bounds are largely based on previous studies (see `itchmodel::get_par_bounds`) and ensure that parameters take sensible values. The nonlinear constraints (`DEoptimR` only) ensure that  that P(choosing LL) > 0.95 when SS amount equals €0 and P(choosing LL) < 0.05 0 when SS amount equals the LL amount (i.e. resulting in more meaningful parameter values).

Alternatively, if `params$optimize` is set to `FALSE`, the parameter values specified in `params$par_vals` are used to compute the log-likelihood. This is useful if you want to test whether other parameter value combinations provide a better fit. 

## Make model predictions based on best-fitting parameters

After fitting, the predicted data are prepared for plotting.

```{r Make model predictions based on best-fitting parameters}
# Put parameter values in right format for tidying
if (params$algorithm == "DEoptim") {
  par_vals <- optim_out$member$bestmem
  names(par_vals) <- par_names
} else if (params$algorithm == "DEoptimR") {
  par_vals <- optim_out$par
  names(par_vals) <- par_names
}

par_vals_output <-
  dplyr::bind_rows(par_vals) %>%
  dplyr::mutate(participant_id = params$participant_id,
                model_name = params$model_name,
                parameterization = params$parameterization,
                bound_settings = params$bound_setting,
                algorithm = params$algorithm) %>%
  dplyr::select(participant_id, model_name, parameterization, bound_settings, dplyr::everything())

# Retrieve observed data, predicted data, and intermediate modeling parameters
obs_and_prds <- 
  cmdsddfeitc::tidy_obs_prd_choice_rt(return_var = 'all',
                                      obs = expt_trials, 
                                      model = params$model_name, 
                                      pmz = stringr::str_c(task_version, params$parameterization, sep = "_"),
                                      parameters = par_vals_output)
```

## Determine indifference points and area under the curve based on model fits

```{r Determine area under the curve based on model fits}
prds <- 
  obs_and_prds$all_nested %>%
  dplyr::mutate(ip = purrr::pmap(.l = list(parameters = .$parameters,
                                           frame = as.character(.$frame)),
                                 .f = predict_ip,
                                 m_l = rep(43.52, length(delays_ip)),
                                 t_l = delays_ip)) %>%
  dplyr::mutate(auc = purrr::pmap(.l = list(y = .$ip),
                                  .f = DescTools::AUC,
                                  x = delays_ip,
                                  method = "trapezoid"))
```

## Tidy choice probability data for plotting

```{r Tidy choice probability data for plotting}
if (params$visualize) {
  prd_pll_for_plot <- 
    obs_and_prds$prd_nested %>% 
    dplyr::select(frame, stimuli, p_ll) %>% 
    tidyr::unnest() %>%
    dplyr::mutate(t_l = factor(t_l, 
                               levels = c(2,4,8,16,32,64,128),
                               labels = c("2 days", "4 days", "8 days", "16 days",
                                          "32 days", "64 days", "128 days"),
                               ordered = TRUE))
  
  prd_pll_for_plot
}
```

## Tidy indifference point data and area-under-the-curve data for plotting and writing to disk

```{r Tidy indifference point data for plotting and writing to disk}
prd_ip_data <- 
  prds %>%
  dplyr::select(frame, ip) %>%
  tidyr::unnest() %>%
  dplyr::mutate(delay = rep(delays_ip, nrow(prds)))

prd_ip_data
```

## Tidy response time data for plotting

```{r Tidy response time data for plotting}
if (params$visualize & params$model_name %in% c("DDM", "DFT_CRT")) {

  stimuli <- 
    obs_and_prds$obs_nested %>%
    dplyr::select(-summary_stats) %>%
    tidyr::unnest() %>%
    dplyr::distinct(participant_id, frame, m_s_cat, m_s, t_s, m_l, t_l) %>%
    dplyr::mutate(frame = factor(frame,
                                 levels = itchmodel::get_frames(parameterization),
                                 ordered = TRUE)) %>%
    dplyr::group_by(participant_id, frame) %>%
    tidyr::nest(.key = stimuli)
    
  parameters <- 
    obs_and_prds$all_nested %>%
    dplyr::select(participant_id, frame, parameters)
  
  stim_params_d_tmp <- 
    dplyr::left_join(stimuli, parameters, by = c("participant_id", "frame")) %>%
    dplyr::mutate(d = purrr::pmap(.l = list(frame = as.character(.$frame),
                                            parameters = .$parameters,
                                            stimuli = .$stimuli),
                                  .f = itchmodel::compute_drift_rate,
                                  parameterization = stringr::str_c(task_version, params$parameterization, sep = "_")
                                  )
                  )
  
  if (params$model_name == "DFT_CRT") {
    stim_params_d_tmp <- 
      stim_params_d_tmp %>%
      dplyr::mutate(du = purrr::pmap(.l = list(parameters = .$parameters,
                                               stimuli = .$stimuli,
                                               frame = as.character(.$frame)),
                                     .f = itchmodel::compute_transformation_diffs,
                                     parameterization = stringr::str_c(task_version, params$parameterization, sep = "_"),
                                   variable = "du"),
                    dp = purrr::pmap(.l = list(parameters = .$parameters,
                                               stimuli = .$stimuli,
                                               frame = as.character(.$frame)),
                                     .f = itchmodel::compute_transformation_diffs,
                                     parameterization = stringr::str_c(task_version, params$parameterization, sep = "_"),
                                     variable = "dp")) %>%
      dplyr::mutate(s = purrr::pmap(.l = list(d = .$d,
                                              du = .$du,
                                              dp = .$dp,
                                              parameters = .$parameters),
                                    .f = function(d, du, dp, parameters) {
                                      sqrt(rep(as.double(parameters["w"]), length(d)) * du^2 + (1 - rep(as.double(parameters["w"]), length(d))) * dp^2 - d^2)
                                    }
                                    )
                    )
  }
  
  # Relevant columns
  rel_cols <- c("participant_id","frame","type","m_s_cat","m_s","t_s","m_l","t_l","med_rt") 
  
  stim_d <- stim_params_d_tmp %>% dplyr::select(-parameters) %>% tidyr::unnest()
  parameters <- parameters %>% tidyr::unnest()
  stim_params_d <- 
    dplyr::left_join(x = stim_d, y = parameters, by = c("participant_id", "frame"))
  
  if (params$model_name == "DDM") {
    stim_params_d <- 
      stim_params_d %>%
      dplyr::mutate(med_rt = purrr::pmap_dbl(.l = list(a = .$a,
                                                       v = .$d,
                                                       t0 = .$t0,
                                                       z = 0.5* .$a),
                                             .f = rtdists::qdiffusion,
                                             response = "upper", # For typical values, predictions for median RTs were found not to differ between "lower" and "upper" responses, hence only "upper"
                                             s = 1,
                                             p = 0.5,
                                             scale_p = TRUE)
                  )
  } else if (params$model_name == "DFT_CRT") {
    stim_params_d <- 
      stim_params_d %>%
      dplyr::mutate(med_rt = purrr::pmap_dbl(.l = list(s = .$s,
                                                       a = .$theta_star *.$s,
                                                       v = .$d,
                                                       t0 = .$t0,
                                                       z = 0.5 * .$theta_star *.$s),
                                            .f = rtdists::qdiffusion,
                                            response = "upper", # For typical values, predictions for median RTs were found not to differ between "lower" and "upper" responses, hence only "upper"
                                            p = 0.5,
                                            scale_p = TRUE)
                    )
  }
  
  stim_params_d <- 
      stim_params_d %>%
      dplyr::mutate(type = "prd") %>% 
      dplyr::mutate(t_l = factor(t_l, 
                                 levels = c(2,4,8,16,32,64,128),
                                 labels = c("2 days", "4 days", "8 days", "16 days",
                                            "32 days", "64 days", "128 days"),
                                 ordered = TRUE)) %>%
      dplyr::select(rel_cols)
  
  # Summary stats - observations
  obs_summary_stats <- 
    obs_nested %>% 
    dplyr::mutate(frame = factor(frame,
                                 levels = itchmodel::get_frames(parameterization),
                                 ordered = TRUE)) %>%
    dplyr::select(-stimuli, -observations) %>% 
    tidyr::unnest() %>% 
    dplyr::mutate(type = "obs",
                  m_s_cat = forcats::fct_recode(m_s_cat, 
                                                below_ip = "below IP",
                                                at_ip = "at IP",
                                                above_ip = "above IP"
                                                )
                  ) %>% 
    dplyr::select(rel_cols)
  
  # Merge observed and predicted median RTs
  rt_data_plot <- dplyr::bind_rows(obs_summary_stats, stim_params_d)
  
  
  obs_mdrt_for_plot <- rt_data_plot %>% dplyr::filter(type == "obs") %>% dplyr::ungroup()
  prd_mdrt_for_plot <- rt_data_plot %>% dplyr::filter(type == "prd") %>% dplyr::ungroup()

}
```

# Visualize data

## Optimization process

### Optimization descriptives

```{r Summarize optimization statistics}
optim_stats <- 
  itchmodel::get_fit_stats(optim_output = optim_out, 
                           algorithm = params$algorithm,
                           model = params$model_name, 
                           parameterization = parameterization, 
                           n_data_points = n_data_points,
                           max_iter = params$max_iter)

# n_iter in optim_out does not reflect the actual number of iterations, because we do iterations in a loop
optim_stats$n_iter = n_iter

optim_stats
```

### Best-fitting parameters values and lower and upper bounds

```{r Print best-fitting parameter values}
best_fitting_par_values <- 
  tibble(frame = factor(itchmodel::get_frames(parameterization = parameterization), ordered = TRUE),
         params = itchmodel::get_par_values(x = best_par_val, 
                                            model = params$model_name, 
                                            parameterization = parameterization)
         ) %>%
  dplyr::mutate(r = purrr::map(params, ~ data.frame(t(.)))) %>%
  tidyr::unnest(r) %>%
  dplyr::select(-params)

best_fitting_par_values
free_par_bounds_tibb
```

### Evolution of parameter values over iterations
How did values of free model parameters evolve over iterations?
Did the model optimzation routine converge?
Do best-fitting parameter values end up at bounds


```{r Evolution of parameter values over iterations, out.width="100%"}
if (params$visualize) {
 h_line_data <- 
    free_par_bounds_tibb %>%
    tidyr::gather(key = "key", value = "value", -bound) %>% 
    tidyr::spread(key = bound, value = value)
 
 ggplot2::ggplot(free_par_vals_per_iter_tibb,
                 ggplot2::aes(x = iter,
                              y = value)) +
   ggplot2::facet_wrap("key",
                       scales = "free_y") +
   ggplot2::geom_hline(data = h_line_data,
                       ggplot2::aes(yintercept = lower),
                       color = "red") +
   ggplot2::geom_hline(data = h_line_data,
                       ggplot2::aes(yintercept = upper),
                       color = "red") +
   ggplot2::geom_step() +
   ggplot2::scale_x_continuous(name = "Iteration") +
   ggplot2::scale_y_continuous(name = "Parameter value") +
   cmdsddfeitc::theme_cmfsddfeitc() 
}
```


```{r Evolution of optimization function value over iterations, out.width="100%"}
if (params$visualize) {
  ggplot2::ggplot(optim_val_per_iter_tibb %>% dplyr::slice(1:n_iter),
                  ggplot2::aes(x = iter,
                               y = fun_val)) +
    ggplot2::geom_step() + 
    ggplot2::scale_x_continuous(name = "Iteration") +
    ggplot2::scale_y_continuous(name = "Optimization function value",
                                limits = c(1e1,1e7),
                                trans="log10") +
    cmdsddfeitc::theme_cmfsddfeitc() 
}

```

## Observed vs. predicted data

### Probability of choosing the LL option

This visualization highlights differences between frames, if any
```{r Model fit to the data, out.width="100%"}
if (params$visualize) {
  ggplot2::ggplot(data = prd_pll_for_plot,
                  ggplot2::aes(x = m_s,
                               y = p_ll, 
                               group = frame,
                               color = frame)) +
    ggplot2::facet_wrap("t_l") +
    ggplot2::geom_line() + 
    ggplot2::geom_point(data = obs_for_plotting,
                        ggplot2::aes(x = m_s,
                                     y = p_ll,
                                     color = frame,
                                     shape = m_s_cat),
                        stroke = 1.5) +
    ggplot2::scale_x_continuous(name = "Smaller sooner amount (€)",
                                breaks = c(0, 20, 40),
                                limits = c(0,43.52)
                                ) +
    ggplot2::scale_y_continuous(name = "P(choosing LL)",
                                breaks = seq(0,1,0.5),
                                limits = c(0,1)) +
    ggplot2::scale_shape_manual(name = "SS amount category",
                                values = c(6,1,2)) +
    ggplot2::scale_color_manual(values = cmdsddfeitc::get_aes_values("color", parameterization)) +
    cmdsddfeitc::theme_cmfsddfeitc() + 
    ggplot2::theme(legend.position = "right",
                   legend.direction = "vertical", 
                   legend.box = "vertical")
}
```

This visualization allows for checking model fit more precisely
```{r Model fit to the data as t_l by frame grid, , out.width="100%"}
if (params$visualize) {
  ggplot2::ggplot(data = prd_pll_for_plot,
                  ggplot2::aes(x = m_s,
                               y = p_ll, 
                               color = frame)) +
    # ggplot2::facet_grid(t_l ~ frame) +
    ggplot2::facet_grid(frame ~ t_l) +
    ggplot2::geom_line() + 
    ggplot2::geom_point(data = obs_for_plotting,
                        ggplot2::aes(x = m_s,
                                     y = p_ll,
                                     color = frame,
                                     shape = m_s_cat),
                        stroke = 1) +
    ggplot2::scale_x_continuous(name = "Smaller sooner amount (€)",
                                breaks = c(0, 20, 40),
                                limits = c(0,43.52)
                                ) +
    ggplot2::scale_y_continuous(name = "P(choosing LL)",
                                breaks = seq(0,1,0.5),
                                limits = c(0,1)) +
    ggplot2::scale_shape_manual(name = "SS amount category",
                                values = c(6,1,2)) +
    ggplot2::scale_color_manual(values = cmdsddfeitc::get_aes_values("color", parameterization)) +
    cmdsddfeitc::theme_cmfsddfeitc() + 
    ggplot2::theme(legend.position = "bottom",
                   legend.direction = "vertical", 
                   legend.box = "horizontal")
    # ggplot2::theme(legend.position = "right")
}
```

### Median response times

```{r Observed and predicted median response times, out.width="100%"}

if (params$visualize & params$model_name %in% c("DDM", "DFT_CRT")) {

  ggplot2::ggplot(obs_mdrt_for_plot,
                  ggplot2::aes(x = t_l,
                               y = med_rt,
                               color = m_s_cat)
                  ) +
    ggplot2::facet_wrap("frame", nrow = 1) +
    
    # Geoms
    ggplot2::geom_point(shape = 21) + 
    ggplot2::geom_line(data = prd_mdrt_for_plot,
                       ggplot2::aes(group = m_s_cat)) +
    # Scales
    ggplot2::scale_x_discrete(name = "Delay (days)") +
    ggplot2::scale_y_continuous(name = "Median RT (s)",
                                limits = c(0,10)) +
    ggplot2::scale_color_discrete(name = "SS amount category") +
    # Theme
    cmdsddfeitc::theme_cmfsddfeitc() + 
    ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 90))
}
```

## Predicted indifference point by delay curves

```{r Indifference point by delay curves, out.width="100%"}
if (params$visualize) {
  ggplot2::ggplot(prd_ip_data,
                  ggplot2::aes(x = delay,
                               y = ip, 
                               color = frame)) + 
    ggplot2::geom_line() + 
    
    ggplot2::scale_color_manual(values = cmdsddfeitc::get_aes_values("color", parameterization)) +
    ggplot2::scale_x_continuous(name = "Delay (days)",
                                limits = c(0, 128)) +
    ggplot2::scale_y_continuous(name = "Indifference point (€)",
                                limits = c(0, 43.52)) +
    cmdsddfeitc::theme_cmfsddfeitc()
}
```


# Write data

The directory in which the computational modeling data will be written depends on whether the model optimization procedure converged (`optimization_converged`) or not (`optimization_nonconverged`). Visualizations are not written sepately to disk (only as part of the notebook knitted to an HTML file).

```{r Write data to disk only if model is optimized}

if (params$optimize) {
  
  # Define output directory based on whether all performance criteria were met
  data_output_dir <- 
    ifelse(optim_stats$converged,
           converged_models_dir,
           nonconverged_models_dir
           )
  
  # Write best-fitting model parameters to disk --------------------------------
  
  # Add relevant variables, so that these files can be read and combined into a 
  # larger data frame for additional analysis
  if (params$algorithm == "DEoptim") {
    par_vals <- optim_out$optim$bestmem
    names(par_vals) <- par_names
  } else if (params$algorithm == "DEoptimR") {
    par_vals <- optim_out$par
    names(par_vals) <- par_names
  }
  
  par_vals_output <-
    dplyr::bind_rows(par_vals) %>%
    dplyr::mutate(participant_id = params$participant_id,
                  model_name = params$model_name,
                  parameterization = params$parameterization,
                  bound_settings = params$bound_setting,
                  algorithm = params$algorithm) %>%
    dplyr::select(participant_id, model_name, parameterization, bound_settings, 
                  algorithm, dplyr::everything())
  
  # Make file name human- and machine-readable, so that main results can be read from file name
  best_par_val_file <-
    file.path(data_output_dir,
              sprintf("best_fitting_params_task-%s_pid-%.3d_model-%s_pmz-%s_bounds-%s_algorithm-%s_BIC-%.0f.csv",
                      task_version,
                      params$participant_id, # pid
                      params$model_name, # mode
                      params$parameterization, # pmz
                      params$bound_setting, # bounds,
                      params$algorithm, # algorithm
                      optim_stats$BIC # BIC
                      )
              )
  
  readr::write_csv(par_vals_output,
                   path = best_par_val_file
              )
  print(sprintf("Best-fitting model parameters: %s", best_par_val_file))
  
  # Write optimization statistics to disk --------------------------------------
  
  # Add relevant variables, so that these files can be read and combined into a 
  # larger data frame for additional analysis
  optim_stats_output <-
    optim_stats %>%
    dplyr::mutate(participant_id = params$participant_id,
                  bound_settings = params$bound_setting,
                  algorithm = params$algorithm) %>%
    dplyr::select(participant_id, model, parameterization, bound_settings, 
                  algorithm, dplyr::everything())
  
  
  # Make file name human- and machine-readable, so that main results can be read from file name
  optim_stats_file <-
    file.path(data_output_dir,
              sprintf("optim_stats_task-%s_pid-%.3d_model-%s_pmz-%s_bounds-%s_algorithm-%s_BIC-%.0f.csv",
                      task_version,
                      params$participant_id, # pid
                      params$model_name, # mode
                      params$parameterization, # pmz
                      params$bound_setting, # bounds
                      params$algorithm, # algorithm
                      optim_stats$BIC # BIC
                      )
              )
  
  # Save to disk
  readr::write_csv(optim_stats_output,
                   path = optim_stats_file
              )
  print(sprintf("Optimization statistics: %s", optim_stats_file))
  
  
  # Write evolution of parameter value across iterations to disk -----------------

  par_vals_per_iter <- 
    tibble::as.tibble(par_vals_per_iter) %>% 
    dplyr::mutate(participant_id = params$participant_id,
                  model_name = params$model_name,
                  parameterization = params$parameterization,
                  bound_settings = params$bound_setting,
                  algorithm = params$algorithm,
                  iter = 1:n()) %>%
    dplyr::select(participant_id, model_name, parameterization, bound_settings, 
                  algorithm, iter, dplyr::everything())
    
  par_vals_per_iter_file <-
    file.path(data_output_dir,
              sprintf("evolution_of_params_across_iters_task-%s_pid-%.3d_model-%s_pmz-%s_bounds-%s_algorithm-%s_BIC-%.0f.csv",
                      task_version,
                      params$participant_id, # pid
                      params$model_name, # mode
                      params$parameterization, # pmz
                      params$bound_setting, # bounds
                      params$algorithm, # algorithm
                      optim_stats$BIC # BIC
              )
    )
  
  readr::write_csv(par_vals_per_iter,
                   path = par_vals_per_iter_file
  )
  
  print(sprintf("Evolution of parameter values during optimization: %s", par_vals_per_iter_file))

# Write evolution of optimization function value across iterations to disk -----

  optim_fun_val_per_iter <- 
    tibble::tibble(fun_val = optim_val_per_iter) %>%
    dplyr::mutate(participant_id = params$participant_id,
                  model_name = params$model_name,
                  parameterization = params$parameterization,
                  bound_settings = params$bound_setting,
                  algorithm = params$algorithm,
                  iter = 1:n()) %>%
    dplyr::select(participant_id, model_name, parameterization, bound_settings, 
                  algorithm, iter, dplyr::everything())
    
  optim_fun_val_per_iter_file <-
    file.path(data_output_dir,
              sprintf("evolution_of_fun_val_across_iters_task-%s_pid-%.3d_model-%s_pmz-%s_bounds-%s_algorithm-%s_BIC-%.0f.csv",
                      task_version,
                      params$participant_id, # pid
                      params$model_name, # mode
                      params$parameterization, # pmz
                      params$bound_setting, # bounds
                      params$algorithm, # algorithm
                      optim_stats$BIC # BIC
              )
    )
  
  readr::write_csv(optim_fun_val_per_iter,
                   path = optim_fun_val_per_iter_file
  )  
  
  print(sprintf("Evolution of function value during optimization: %s", optim_fun_val_per_iter_file))
  
  # Write predicted IP data to disk --------------------------------------------
  
  # Add relevant variables, so that these files can be read and combined into a 
  # larger data frame for additional analysis
  prd_ip_output <-
    prd_ip_data %>%
    dplyr::mutate(participant_id = params$participant_id,
                  bound_settings = params$bound_setting,
                  model = params$model_name,
                  parameterization = params$parameterization,
                  algorithm = params$algorithm) %>%
    dplyr::select(participant_id, model, parameterization, bound_settings, 
                  algorithm, dplyr::everything())
  
  
  # Make file name human- and machine-readable, so that main results can be read from file name
  prd_ip_output_file <-
    file.path(data_output_dir,
              sprintf("predicted_indifference_points_task-%s_pid-%.3d_model-%s_pmz-%s_bounds-%s_algorithm-%s_BIC-%.0f.csv",
                      task_version,
                      params$participant_id, # pid
                      params$model_name, # mode
                      params$parameterization, # pmz
                      params$bound_setting, # bounds
                      params$algorithm, # algorithm
                      optim_stats$BIC # BIC
                      )
              )
  
  # Save to disk
  readr::write_csv(prd_ip_output,
                   path = prd_ip_output_file
              )
  print(sprintf("Indifference point data: %s", prd_ip_output_file))
  
  # Write area under the curve to disk -----------------------------------------
  
  # Add relevant variables, so that these files can be read and combined into a 
  # larger data frame for additional analysis
  auc_output <-
    prds %>%
    dplyr::select(frame, auc) %>%
    tidyr::unnest() %>%
    dplyr::mutate(participant_id = params$participant_id,
                  bound_settings = params$bound_setting,
                  model = params$model_name,
                  parameterization = params$parameterization,
                  algorithm = params$algorithm,
                  norm_auc = auc / (43.52 * 128)) %>%
    dplyr::select(participant_id, model, parameterization, bound_settings, 
                  algorithm, dplyr::everything())
  
  # Make file name human- and machine-readable, so that main results can be read from file name
  auc_output_file <-
    file.path(data_output_dir,
              sprintf("auc_task-%s_pid-%.3d_model-%s_pmz-%s_bounds-%s_algorithm-%s_BIC-%.0f.csv",
                      task_version,
                      params$participant_id, # pid
                      params$model_name, # mode
                      params$parameterization, # pmz
                      params$bound_setting, # bounds
                      params$algorithm, # algorithm
                      optim_stats$BIC # BIC
                      )
              )
  
  # Save to disk
  readr::write_csv(auc_output,
                   path = auc_output_file
              )
  print(sprintf("Area under the curve: %s", auc_output_file))
}
```
